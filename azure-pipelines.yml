# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/en-us/azure/devops/pipelines/languages/python?view=vsts

# Capabilities and limitations:
# https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=vsts&tabs=yaml#capabilities-and-limitations
# - Provide at least 10 GB of storage for your source and build outputs.
# - Can run jobs for up to 360 minutes (6 hours).

# Notes on pipeline definitions:
#
# the number after @ in task definition indicates the azure internal version of the specific task, e.g:
# - task: CondaEnvironment@1
# means use azure's CondaEnvironment's version 1, so need to check the docs for each specific task's desired (usually latest) version. If later 1.2 is released then use:
# - task: CondaEnvironment@1.2
# instead
#
# job name must match r'\w+' (no '-', but '_' ok)
#
# Build environments: Available vmImage values: 'Ubuntu-16.04', 'macOS-10.13', 'VS2017-Win2016'
#

jobs:


################
### MacOS CI ###
################

- job: MacOS_PyPI
  pool:
    vmImage: 'macOS-10.13'

  # Run the pipeline with multiple Python versions
  strategy:
    matrix:
      Python36:
        python.version: '3.6'
    maxParallel: 4

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '$(python.version)'
      architecture: 'x64'

     # Install dependencies and fastai git HEAD or PR
  - script: |
      export PYTHONPATH=`pwd`/custom:$PYTHONPATH
      export PATH=`pwd`/custom/bin:$PATH
      mkdir `pwd`/custom
      pip install --prefix=`pwd`/custom --upgrade pip
      pip install --prefix=`pwd`/custom --upgrade setuptools
      pip install --prefix=`pwd`/custom torch_nightly -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html
      # test that we can install fastai package (and torchvision)
      pip install --prefix=`pwd`/custom fastai
      pip uninstall -y fastai
      # install editable fastai, which tests the HEAD or PR
      pip install --prefix=`pwd`/custom -e .[dev]
      pip install --prefix=`pwd`/custom asn1crypto==0.24.0 cffi==1.11.5 cryptography==2.4.1 mkl-fft==1.0.6 mkl-random==1.0.1 mkl==2018.0.3 ninja==1.8.2 pycosat==0.6.3 pycparser==2.19 pyopenssl==18.0.0 pysocks==1.6.8 pytest-runner==4.2 pytest==4.0.0 ruamel-yaml==0.15.46
      pip install --prefix=`pwd`/custom readline intel-openmp olefile libtiff
      pip install --prefix=`pwd`/custom google
      # workaround for matplotlib bug on macOS: https://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python
      mkdir -p ~/.matplotlib
      echo "backend: TkAgg" >> ~/.matplotlib/matplotlibrc
    displayName: 'Upgrade pip and setuptools, install pytorch and fastai deps'
    continueOnError: false

     # Show PyPi Build Env
  - script: |
      export PYTHONPATH=`pwd`/custom:$PYTHONPATH
      export PATH=`pwd`/custom/bin:$PATH
      echo "cwd:" `pwd`
      python -c 'import fastai; fastai.show_install(0)'
      pip list | egrep -v '^(Package|-----)' | perl -ne 's/_/-/g; @x=split /\s+/, lc $_; print "$x[0]==$x[1]\n"' | sort | uniq
    displayName: 'Show build environment'
    continueOnError: false

    # Run Tests
  - script: |
      export PYTHONPATH=`pwd`/custom:$PYTHONPATH
      export PATH=`pwd`/custom/bin:$PATH
      # make the data dir local
      mkdir myfastai
      ln -s `pwd`/myfastai ~/.fastai
      ls -l ~/.fastai
      py.test tests --cache-clear --junitxml=result.xml
      make test
      ls -l ~/.fastai/
      ls -l ~/.fastai/data
      ls -l myfastai/
      ls -l myfastai/data
    displayName: 'Run tests'
    continueOnError: true

    # Publish test results to the Azure DevOps server
  - task: PublishTestResults@2
    inputs:
      testResultsFiles: 'result.xml'
      testRunTitle: 'Python $(python.version)'
      condition: succeededOrFailed()

    # Jupyter Test
  - script: |
      # 1. test that we can run jupyter (have all the deps figured out)
      # 2. that we can execute a fastai nb
      jupyter nbconvert --execute --ExecutePreprocessor.timeout=600 --to notebook examples/tabular.ipynb
      # 3. check for expected in the output string and bail if it's not there.
      echo "Testing expected output"
      grep "Total time" examples/tabular.nbconvert.ipynb
      # 4. test that python kernel is available
      echo "Testing jupyter kernelspec list"
      jupyter kernelspec list | grep python3
    displayName: 'Run jupyter notebook tests'
    continueOnError: false



- job: 'MacOS_Conda'

  pool:
    vmImage: 'macOS-10.13'

  # Run the pipeline with multiple Python versions
  strategy:
    matrix:
      Python36:
        python.version: '3.6'

    # Increase the maxParallel value to simultaneously run the job for all versions in the matrix (max 10 for free open-source)
    maxParallel: 4

  steps:
    # Set the UsePythonVersion task to reference the matrix variable for its Python version
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '$(python.version)'
      architecture: 'x64'

  - script: sudo install -d -m 0777 /usr/local/miniconda/envs/
    displayName: Fix Conda permissions

    # Conda setup environment.
    # https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/package/conda-environment?view=vsts
    #
  - task: CondaEnvironment@0
    inputs:
      environmentName: 'fastai-cpu'
      packageSpecs: 'python=$(python.version)'

    # Install dependencies and fastai git HEAD or PR
  - script: |
      conda activate fastai-cpu
      conda install -y conda
      conda install -y pip setuptools
      # pytorch + torchvision
      conda install -y -c pytorch pytorch-nightly
      conda install -y -c fastai torchvision-nightly
      # test that we can install fastai package
      conda install -y -c fastai fastai
      conda uninstall -y fastai
      # install editable fastai, which tests the HEAD or PR
      pip install -e .[dev]
      conda install -y -f regex=2018.11.22 -c conda-forge
      conda install -y -f typing==3.6.6 urllib3==1.24.1 wheel==0.31.1
      conda install -y -f matplotlib=3.0.2 -c conda-forge
      conda install -y -f python=3.6.5

      # workaround for matplotlib bug on macOS: https://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python
      mkdir -p ~/.matplotlib
      echo "backend: TkAgg" >> ~/.matplotlib/matplotlibrc
    displayName: 'Upgrade pip/conda/setuptools. Install deps, pytorch and fastai'
    continueOnError: false

    # Install Test deps
  - script: |
      conda install -y pytest pytest-runner
    displayName: 'Install test deps'
    continueOnError: false

     # Show Conda Build Env
  - script: |
      echo "cwd:" `pwd`
      python -c 'import fastai; fastai.show_install(0)'
      conda list | egrep -v '^#' | perl -ne 's/_/-/g; @x=split /\s+/, lc $_; print "$x[0]==$x[1]\n"' | sort | uniq
    displayName: 'Show build environment'
    continueOnError: false

    # Run Tests
  - script: |
      py.test tests --cache-clear --junitxml=result.xml
    displayName: 'Run tests'
    continueOnError: false

    # Publish test results to the Azure DevOps server
  - task: PublishTestResults@2
    inputs:
      testResultsFiles: 'result.xml'
      testRunTitle: 'Python $(python.version)'
      condition: succeededOrFailed()

    # Jupyter Test
  - script: |
      # 1. test that we can run jupyter (have all the deps figured out)
      # 2. that we can execute a fastai nb
      jupyter nbconvert --execute --ExecutePreprocessor.timeout=600 --to notebook examples/tabular.ipynb
      # 3. check for expected in the output string and bail if it's not there.
      echo "Testing expected output"
      grep "Total time" examples/tabular.nbconvert.ipynb
      # 4. test that python kernel is available
      echo "Testing jupyter kernelspec list"
      jupyter kernelspec list | grep python3
    displayName: 'Run jupyter notebook tests'
    continueOnError: false
